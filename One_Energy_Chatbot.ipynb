{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install the necessary libraries"
      ],
      "metadata": {
        "id": "YPz4pQWJdHVC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hXrY9LeclzO",
        "outputId": "3d34b47d-890f-4399-a991-8e5d139f043e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/276.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m276.5/276.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai -q\n",
        "!pip install llama-index -q\n",
        "!pip install PyPDF2 -q\n",
        "!pip install gradio -q\n",
        "!pip install pypdf -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the necessary libraries"
      ],
      "metadata": {
        "id": "tB_AnqtkDru5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain import OpenAI\n",
        "import openai\n",
        "import gradio as gr\n",
        "import sys\n",
        "import api_secret\n",
        "key = api_secret.API_KEY\n",
        "openai.api_key = key\n",
        "os.environ[\"OPENAI_API_KEY\"] = key\n",
        "from llama_index import SimpleDirectoryReader, GPTListIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper, load_index_from_storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "KvsjBvbwlfny",
        "outputId": "5830b39c-ff8e-484a-fd15-b8e3478134ca",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a9934e249cd2f01433.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a9934e249cd2f01433.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the chatbot on custom data located in \"docs\" folder"
      ],
      "metadata": {
        "id": "QmvGd1_yDv5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_index(directory_path):\n",
        "    max_input_size = 4096\n",
        "    num_outputs = 512\n",
        "    max_chunk_overlap = 0.1 #20\n",
        "    chunk_size_limit = 600\n",
        "\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
        "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "    index = GPTVectorStoreIndex(documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
        "    index.storage_context.persist(persist_dir=\"index.json\")\n",
        "    return index\n",
        "\n",
        "index = construct_index(\"docs\")"
      ],
      "metadata": {
        "id": "mROH6TKbDY_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Design a website with a simple UI for the chatbot"
      ],
      "metadata": {
        "id": "yvawLDspD3D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(input_text):\n",
        "    query_engine = index.as_query_engine()\n",
        "    response = query_engine.query(input_text)\n",
        "    return response.response\n",
        "\n",
        "iface = gr.Interface(fn=chatbot,\n",
        "                     inputs=gr.Textbox(lines=7, label=\"Enter your text\"),\n",
        "                     outputs=\"text\",\n",
        "                     title=\"One Energy AI Chatbot\")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "BX_a-Vr1Df15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}